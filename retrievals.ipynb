{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CS1 - Install Libraries, define main variables, and some basic functions ####\n",
    "You can convert this notebook to HTML by entering the following command in the VS Code terminal window:\n",
    "\n",
    "`jupyter nbconvert --no-input --to html retrievals.ipynb`\n",
    "\n",
    "_Make sure that the terminal window is running in the same virtual environment.  On my Mac computer, if the terminal prompt is `(.venv) $ ` then I know it is running in the virtual environment.  Otherwise, I enter `source venv/bin/activate` to put it into the virtual environment_\n",
    "\n",
    "**CS1, CS2, CS3, etc. are Code cells in the notebook.  The code does not appear in the HTML output.  You have to look into the notebook file (`introduction.ipynb`) to see the code contained in CS1, CS2, etc..**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/Halim/git/probot\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANT :\n",
    "# I am running this in the local virtual environment venv.  The python libraries installed when running introduction.ipynb\n",
    "# do not have to be re-installed here as they are already installed in the virtual environment.\n",
    "#\n",
    "# The following are the additional libraries used in the notebook\n",
    "#\n",
    "# I set my OPENAI_API_KEY in a .env file.  You can also set it in your environment variables.\n",
    "# The following two lines read the .env file and set the environment variable.\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "import math\n",
    "import numpy as np\n",
    "# import melib\n",
    "# from melib.xt import mdx\n",
    "# import the functions in the local python file ute.py\n",
    "from ute import set_openai_key, rdweb, sepstr, get_embedding, SEP, cosine_similarity\n",
    "# The following are the variables used in the notebook\n",
    "\n",
    "PIE=math.pi\n",
    "SECTION=0\n",
    "MD=None\n",
    "Chapter=\"retrievals\"\n",
    "#\n",
    "# Define the md() function to display markdown text\n",
    "from IPython.display import display, Markdown\n",
    "def md(s):\n",
    "    display(Markdown(s))\n",
    "\n",
    "# Establish OpenAI API key (see below for how to get one)\n",
    "# import os\n",
    "# import openai\n",
    "# from openai import OpenAI\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "# client = OpenAI()\n",
    "# LLM=\"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CS1 Ends ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CS2 ####\n",
    "\n",
    "Program flow control variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "RECREATE_SHORT=False\n",
    "RECREATE_FULL=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CS2 Ends ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CS3 ####\n",
    "Computations specific to this notebook.  The results are used in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following function creates a list of all pages under the given url and saves it to a file\n",
    "def create_page_list(url):\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    links = soup.find_all('a')\n",
    "    page_list=[]\n",
    "    for link in links:\n",
    "        s=link.get('href')\n",
    "        print(s)\n",
    "        if not s==None and not s.endswith('/comments') and not s in page_list:\n",
    "            page_list.append(s)\n",
    "    with open('page_list.txt', 'w') as f:\n",
    "        for item in page_list:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    return page_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following function reads the file `filename`. This file is orgaanised as pairs\n",
    "# of lines. The first line in each pair is the url address and the second line is the\n",
    "# title of the page.  The function returns a list of tuples where each tuple is the\n",
    "# url and the title.\n",
    "def read_page_list(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    page_list=[]\n",
    "    for i in range(0,len(lines),2):\n",
    "        page_list.append((lines[i].strip(),lines[i+1].strip()))\n",
    "    return page_list\n",
    "fullfile='data/general_list.txt'\n",
    "full_list=read_page_list(fullfile)\n",
    "shortfile='data/short_list.txt'\n",
    "short_list=read_page_list(shortfile)\n",
    "short_list_embedfile='data/short_list_embed'\n",
    "full_list_embedfile='data/full_list_embed'\n",
    "# for pair in page_list:\n",
    "#     print(pair)\n",
    "\n",
    "# The following function opens the text file `filename`. This file is orgaanised as pairs\n",
    "# of lines. The first line in each pair is the url address and the second line is the\n",
    "# title of the page.  The function reads the `n`th pair of lines and returns the url and\n",
    "# the title.\n",
    "def read_page(filename,n):\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return lines[2*n].strip(),lines[2*n+1].strip()\n",
    "\n",
    "# (url, title)=read_page(fullfile,8)\n",
    "# print(url)\n",
    "# print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the web pages in the short_list, separate them into sections\n",
    "# separated by SEP imported from ute and embed each section separately.  Create the embedding array.\n",
    "# The embedding array is saved in the file 'data/short_list_embeddings.npy'\n",
    "# The embedding array is a numpy array of shape (N,512) where N is the number of sections\n",
    "# and 512 is the number of dimensions in the embedding space.\n",
    "\n",
    "embeddings=[]\n",
    "\n",
    "def headandtail(embeddings, MD):\n",
    "    def writeone(v, MD):\n",
    "        MD.write(\"%.5f, %.5f, %.5f, ..., %.5f, %3d, %3d\\n\\n\"%(v[0], v[1], v[2], v[-3],v[-2],v[-1]))\n",
    "    for (iv,v) in enumerate(embeddings[0:3]):\n",
    "        writeone(v, MD)\n",
    "    MD.write(\"...\\n\\n\")\n",
    "    for (iv,v) in enumerate(embeddings[-3:]):\n",
    "        writeone(v, MD)\n",
    "\n",
    "def create_embeddings(filename, listname):\n",
    "    global embeddings\n",
    "    embeddings=[]\n",
    "    set_openai_key()\n",
    "    for (itext,pair) in enumerate(listname):\n",
    "        url=pair[0]\n",
    "        text=rdweb(url, None)\n",
    "        sa=sepstr(text, SEP)\n",
    "        MD.write(\"%d. %s : \"%(itext+1,pair[1]))\n",
    "        for (isegment, s) in enumerate(sa):\n",
    "            v=get_embedding(s)\n",
    "            w=np.append(v,[itext,isegment])\n",
    "            embeddings.append(w)\n",
    "        MD.write(\"%d segments embedded to %d-long vectors\"%(isegment, len(v)))\n",
    "        MD.write(\"\\n\")\n",
    "    # Save the embeddings to a file\n",
    "    np.save(filename,embeddings)\n",
    "    MD.write(\"Embeddings saved in file %s.npy\\n\\n\"%filename)\n",
    "    MD.write(\"### Extra two members for the embedding vectors ###\\n\\n\\\n",
    "The last two members of each embedding vector are the index of the page and the index of the segment in the page.\\n\\\n",
    "To demonstrate this, I print below the first three and last three members oof all the embedding vectors:\\n\\n\")\n",
    "    headandtail(embeddings, MD)\n",
    "    MD.write(\"\\n\\nWe have to remember to discard the last two numbers when we compare the query text embedding \\\n",
    "             against these embedding vectors.\\n\\n\")\n",
    "    \n",
    "def load_embeddings(filename):\n",
    "    global embeddings\n",
    "    embeddings=np.load(filename+\".npy\")\n",
    "    MD.write(\"Embeddings were read from file %s.npy\\n\\n\"%filename)\n",
    "    MD.write(\"The following shows the first three and last three members of each embedding vector:\\n\\n\")\n",
    "    headandtail(embeddings, MD)\n",
    "    MD.write(\"\\n\\nThe last two are the index to the page list and the index to the segment in the page.\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CS3 ends ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# MyBlogPosts #\n",
       "\n",
       "#### Table of Contents ####\n",
       "\n",
       "_2023_\n",
       "\n",
       "|Section|Title|\n",
       "|:------|:-------|\n",
       "|1|<a href=\"#Getting-my-posts-ready-for-embedding\">Getting my posts ready for embedding</a>|\n",
       "|2|<a href=\"#Create-embeddings-for-the-short-list\">Create embeddings for the short list</a>|\n",
       "|3|<a href=\"#Create-embeddings-for-the-long-list\">Create embeddings for the long list</a>|\n",
       "|4|<a href=\"#Simple-queries\">Simple queries</a>|\n",
       "\n",
       "\n",
       "This notebook is about creating embeddings for my substack blog posts. I will use OpenAI API to generate embeddings. To run this notebook you need to have an OpenAI account.  Do not try to run this notebook without trying my earlier notebooks:\n",
       "\n",
       "* [`introduction.ipynb`](https://github.com/Gurgenci/probot/blob/main/introduction.ipynb)\n",
       "* [`embeddings.ipynb`](https://github.com/Gurgenci/probot/blob/main/embeddings.ipynb)\n",
       "\n",
       "Also read my earlier posts under `AI Stuff`.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TOC=[\"Getting my posts ready for embedding\", \"Create embeddings for the short list\",  \\\n",
    "     \"Create embeddings for the long list\", \"Simple queries\"\n",
    "     ]\n",
    "MD=mdx(Chapter, SECTION, title=\"MyBlogPosts\")\n",
    "MD.toc(TOC,\"2023\")\n",
    "#\n",
    "# \n",
    "MD.write('This notebook is about creating embe\\\n",
    "ddings for my substack blog posts. I will use OpenAI API to generate embeddin\\\n",
    "gs. To run this notebook you need to have an OpenA\\\n",
    "I account.  Do not try to run this notebook without trying my earlier notebooks:\\n\\n\\\n",
    "* [`introduction.ipynb`](https://github.com/Gurgenci/probot/blob/main/introduction.ipynb)\\n\\\n",
    "* [`embeddings.ipynb`](https://github.com/Gurgenci/probot/blob/main/embeddings.ipynb)\\n\\n\\\n",
    "Also read my earlier posts under `AI Stuff`.\\n\\n')\n",
    "if RECREATE_SHORT:\n",
    "     MD.write(\"**Important** : Short List Embeddings were recreated and saved into the `data` folder. \\\n",
    "              Make RECREATE_SHORT False if you do not want to recreate the short list embeddings in future RUN ALLs.  \\n\\n\")\n",
    "if RECREATE_FULL:\n",
    "     MD.write(\"**Important** : Long List Embeddings were recreated and saved into the `data` folder. \\\n",
    "              Make RECREATE_FULL False if you do not want to recreate the long list embeddings in future RUN ALLs.  \\n\\n\")\n",
    "md(MD.out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Getting my posts ready for embedding #\n",
       "\n",
       "I think my posts are too long and I divided them into segments using the separator `-+-+-+-+`.           I also thought trying a second level separation using the string `-*-*-` but then I thought this          would be an overkill.  I will use only the first level separator to create embeddings.\n",
       "\n",
       "The next task was to create a list of all my posts.  I wanted to create this list automatically and tried          the function `create_page_list()` in CS2 above to create a list of all my posts.\n",
       "\n",
       "Unfortunately, this function did only get most recent posts and missed          the erarlier pages.  I asked ChatGPT about it and its response was:\n",
       "\n",
       ">Substack, as a popular blogging platform, typically organizes posts in a feed,          which can use pagination to manage the display of a large number of posts.          Pagination in web platforms like Substack is often implemented to improve          load times and user experience by not loading all content at once.\n",
       "\n",
       "SInce we did not know what pagination method Substack used, it was not possible to          create a list of all my posts automatically.  I had to create the list manually.\n",
       "\n",
       "I created the list of all my posts in the file `general_list.txt` and read it into             the list `full_list`.\n",
       "\n",
       "The list `full_list` has the following entries:\n",
       "\n",
       "* The Requiem for a Dream: Israel's Untaken Paths\n",
       "* The importance of elite consensus\n",
       "* OpenAI astounds us again\n",
       "* Why did Elon Musk buy Twitter?\n",
       "* Elon Musk: The Spaceman\n",
       "* Let us talk about Elon Musk\n",
       "* Despicable Acts - Part 2\n",
       "* Despicable Deeds\n",
       "* \"ROGUE Age\" & Climate Change: Unpredictable Global Transitions\n",
       "* ROGUE Age Accessory #1 - Population\n",
       "* ROGUE - Renaissance on globe with upheavals everywhere\n",
       "* The Great Stagnation ends but for whom?\n",
       "* When the rivers run dry\n",
       "* The Voice Referendum in Australia\n",
       "* Conspiracy Theories - Part 2\n",
       "* Conspiracy Theories - Part 1\n",
       "* How many more ruins in Great Britain?\n",
       "* While watching Utopia on ABC\n",
       "* Lying Oracles and the 'Anyone and No Holds Barred' war against Musk\n",
       "* The one thing necessary for the triumph of ignorance is for wise men to stop talking to the uninformed\n",
       "* Will there be a war?\n",
       "* How do we select our information sources?\n",
       "* Do we know why we know what we know?\n",
       "* Does layering affect heat loss?\n",
       "* Elections in Turkey\n",
       "* Monster Wave soon to hit your shore\n",
       "* Try counting carbons not calories to have a better control on your weight\n",
       "* Bridge Fixture for Five Players\n",
       "* The Attainment of Happiness\n",
       "* Competent intelligence is here, will it do engineering?\n",
       "* The Prodigal Bird returns\n",
       "* Earthquake Thoughts and Facts\n",
       "* Why were so many buildings destroyed?\n",
       "To reduce the costs of debugging the embedding process, I created a shorter list of posts in the file `short_list.txt`.\n",
       "\n",
       "The list `short_list` has the following entries:\n",
       "\n",
       "* The Requiem for a Dream: Israel's Untaken Paths\n",
       "* Conspiracy Theories - Part 2\n",
       "* Conspiracy Theories - Part 1\n",
       "I will first use the shorter list in this notebook.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SECTION+=1\n",
    "SECTION=1\n",
    "MD=mdx(Chapter, SECTION, TOC[SECTION-1])\n",
    "MD.write(\"I think my posts are too long and I divided them into segments using the separator `-+-+-+-+`.  \\\n",
    "         I also thought trying a second level separation using the string `-*-*-` but then I thought this \\\n",
    "         would be an overkill.  I will use only the first level separator to create embeddings.\\n\\n\")\n",
    "MD.write(\"The next task was to create a list of all my posts.  I wanted to create this list automatically and tried \\\n",
    "         the function `create_page_list()` in CS2 above to create a list of all my posts.\\n\\n\")\n",
    "MD.write(\"Unfortunately, this function did only get most recent posts and missed \\\n",
    "         the erarlier pages.  I asked ChatGPT about it and its response was:\\n\\n\")\n",
    "MD.write(\">Substack, as a popular blogging platform, typically organizes posts in a feed, \\\n",
    "         which can use pagination to manage the display of a large number of posts. \\\n",
    "         Pagination in web platforms like Substack is often implemented to improve \\\n",
    "         load times and user experience by not loading all content at once.\\n\\n\")\n",
    "MD.write(\"SInce we did not know what pagination method Substack used, it was not possible to \\\n",
    "         create a list of all my posts automatically.  I had to create the list manually.\\n\\n\")\n",
    "MD.write(\"I created the list of all my posts in the file `general_list.txt` and read it into \\\n",
    "            the list `full_list`.\\n\\n\")\n",
    "MD.write(\"The list `full_list` has the following entries:\\n\\n\")\n",
    "for pair in full_list:\n",
    "    MD.write(\"* \"+pair[1]+\"\\n\")\n",
    "MD.write(\"To reduce the costs of debugging the embedding process, I created a shorter list of posts in the file `short_list.txt`.\\n\\n\")\n",
    "MD.write(\"The list `short_list` has the following entries:\\n\\n\")\n",
    "for pair in short_list:\n",
    "    MD.write(\"* \"+pair[1]+\"\\n\")\n",
    "MD.write(\"I will first use the shorter list in this notebook.\\n\\n\")        \n",
    "MD.write(\"\\n\\n\")\n",
    "md(MD.out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Create embeddings for the short list #\n",
       "\n",
       "I will now read the web pages in the `short_list` and create embeddings for each section.           I will save the embeddings in a file in the `data` folder.\n",
       "\n",
       "Embeddings were read from file data/short_list_embed.npy\n",
       "\n",
       "The following shows the first three and last three members of each embedding vector:\n",
       "\n",
       "-0.00478, 0.01175, -0.00854, ..., -0.02872,   0,   0\n",
       "\n",
       "-0.01794, -0.00800, -0.00239, ..., -0.02420,   0,   1\n",
       "\n",
       "-0.01119, -0.02013, -0.01121, ..., -0.01077,   0,   2\n",
       "\n",
       "...\n",
       "\n",
       "-0.02132, -0.02397, -0.01467, ..., -0.01877,   2,   6\n",
       "\n",
       "0.00630, -0.01048, 0.01402, ..., -0.01330,   2,   7\n",
       "\n",
       "0.01223, -0.01027, -0.01069, ..., -0.02849,   2,   8\n",
       "\n",
       "\n",
       "\n",
       "The last two are the index to the page list and the index to the segment in the page.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SECTION+=1\n",
    "SECTION=2\n",
    "MD=mdx(Chapter, SECTION, TOC[SECTION-1])\n",
    "MD.write(\"I will now read the web pages in the `short_list` and create embeddings for each section.  \\\n",
    "         I will save the embeddings in a file in the `data` folder.\\n\\n\")\n",
    "if RECREATE_SHORT:\n",
    "    create_embeddings(short_list_embedfile, short_list)\n",
    "else:\n",
    "    load_embeddings(short_list_embedfile)\n",
    "MD.write(\"\\n\\n\")\n",
    "md(MD.out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Create embeddings for the long list #\n",
       "\n",
       "I am happy with the way I created the embeddings for the short list.           I will now create embeddings for the long list.\n",
       "\n",
       "Embeddings were read from file data/full_list_embed.npy\n",
       "\n",
       "The following shows the first three and last three members of each embedding vector:\n",
       "\n",
       "-0.00478, 0.01175, -0.00854, ..., -0.02872,   0,   0\n",
       "\n",
       "-0.01794, -0.00800, -0.00239, ..., -0.02420,   0,   1\n",
       "\n",
       "-0.01119, -0.02015, -0.01128, ..., -0.01072,   0,   2\n",
       "\n",
       "...\n",
       "\n",
       "-0.00341, -0.00585, -0.00933, ..., -0.02407,  32,   7\n",
       "\n",
       "-0.00294, -0.00936, -0.00163, ..., -0.03766,  32,   8\n",
       "\n",
       "0.00450, -0.00034, -0.02252, ..., -0.04635,  32,   9\n",
       "\n",
       "\n",
       "\n",
       "The last two are the index to the page list and the index to the segment in the page.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SECTION+=1\n",
    "SECTION=3\n",
    "MD=mdx(Chapter, SECTION, TOC[SECTION-1])\n",
    "MD.write(\"I am happy with the way I created the embeddings for the short list.  \\\n",
    "         I will now create embeddings for the long list.\\n\\n\")\n",
    "if RECREATE_FULL:\n",
    "    create_embeddings(full_list_embedfile, full_list)\n",
    "else:\n",
    "    load_embeddings(full_list_embedfile)\n",
    "MD.write(\"\\n\\n\")\n",
    "md(MD.out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Simple queries #\n",
       "\n",
       "Last two cells of this notebook are to be used interactively to query the embeddings.\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SECTION+=1\n",
    "SECTION=4\n",
    "MD=mdx(Chapter, SECTION, TOC[SECTION-1])\n",
    "MD.write(\"Last two cells of this notebook are to be used interactively to query the embeddings.\\n\\n\")\n",
    "MD.write(\"\\n\\n\")\n",
    "md(MD.out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter your query ###\n",
    "The following cell will let the user enter a query and it will then  retrieve the matching page(s) and segment(s).  You can run it a repeated number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afbbf22728e48d7934c43a8105fd82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='String:', placeholder='What is your question ?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13f6ae9af1e44fe88a69a1f62b7ebaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Click Me', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# The following function sorts the np array `vsim` from highest to lowest and returns the sorted indices\n",
    "def sort_indices(a):\n",
    "    return np.argsort(a)[::-1]\n",
    "\n",
    "vsim=np.zeros(len(embeddings))\n",
    "\n",
    "text = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='What is your question ?',\n",
    "    description='String:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "button = widgets.Button(description=\"Click Me\")\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    global vsim\n",
    "    query=text.value\n",
    "    query_embedding=get_embedding(query)\n",
    "    max_similarity=0\n",
    "    for i in range(len(embeddings)):\n",
    "        w=embeddings[i]\n",
    "        v=w[:-2]\n",
    "        similarity = cosine_similarity(v, query_embedding)\n",
    "        vsim[i]=similarity\n",
    "        if similarity>max_similarity:\n",
    "            max_similarity=similarity\n",
    "            max_index=i \n",
    "    print(\"You asked : %s\"%query)\n",
    "    print(\"The following are the top 10 matches:\")\n",
    "    sorted_indices=sort_indices(vsim)\n",
    "    # print(sorted_indices)\n",
    "    for x in sorted_indices[0:10]:\n",
    "        jpage=int(embeddings[x][-2])\n",
    "        jsegment=int(embeddings[x][-1])\n",
    "        (url, title)=read_page(fullfile,jpage)\n",
    "        pagetext=rdweb(url, None)\n",
    "        paginatedtext=sepstr(pagetext, SEP)\n",
    "        print(\"%d, %d, %.5f, %s: '%s ...'\"%(jpage,jsegment,vsim[x], title, paginatedtext[jsegment][0:40]))\n",
    "   \n",
    "    # print(\"Your question is related to Page %d, Segment %d\"%(embeddings[max_index][-2],embeddings[max_index][-1]))\n",
    "\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "display(text, button)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print segment text ###\n",
    "The following cell can be used a segment in one of the pages in the `fullfile`.  Change `jpage` and `jseg` to the values you are interested. You can run it a repeated number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 16, Segment 4\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The cancellation of the 2026 Melbourne Commonwealth Games with impunity last month (and Alberta getting out of the 2020 Commonwealth Games) is another indication of the status of the former Empire.Then there is Brexit.  Historians will explore the role of Brexit in Britain's decline and might be able to identify the factors that forced Brexit, which at the moment is imponderable for me. What I understood from the Brexit incident is that the ruling elites of British society are not able form a single unified prosperous future vision for the country. Stefan Dercon explains this issue of elite consensus requirement very well in his book Development Gambling. I may write about Dercon’s book some other time.When the American revolutionaries won the Battle of Saratoga against the royal armies in 1777, a student approached Adam Smith, muttering; \"Burgoyne is defeated. We're ruined.\" Smith replied: \"My boy, there is a lot of ruin in a nation.\" With all the setbacks of the twentieth century and post-Brexit problems, how many ruins are still left in Britain, we shall see.ReferencesMcCartney, S., and J. Stittle. 2017. ''A Very Costly Industry': The cost of Britain's privatised railway', _Critical perspectives on accounting_, 49: 1-17.Steer-Davies-Gleave. 2016. \"Study on the prices and quality of rail passenger services.\" In, edited by European Commission Directorate General for Mobility and Transport. European Commission Directorate General for Mobility and Transport.Short TakesPower Engineering International, 3 Ağustos 2023"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jpage=16 # Entry in the full list\n",
    "jseg=4\n",
    "(url, title)=read_page(fullfile,jpage)\n",
    "pagetext=rdweb(url, None)\n",
    "paginatedtext=sepstr(pagetext, SEP)\n",
    "print(\"Page %d, Segment %d\"%(jpage,jseg))\n",
    "md(paginatedtext[jseg])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
